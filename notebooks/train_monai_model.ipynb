{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use a custom model quickly\n",
    "\n",
    "Reuse the data(loader) from the \"ML pipe\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dba488f6c9898c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the libraries needed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e42e792c194f5e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "from src.run_training import parse_args_to_dict\n",
    "from src.training.experiment import define_experiment_data\n",
    "from src.utils.config_utils import import_config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T00:04:59.374085841Z",
     "start_time": "2023-10-25T00:04:59.343936639Z"
    }
   },
   "id": "c200b12aa14f2287"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you run this Notebook on Colab, you need to install the Virtual Environment with Poetry yourself (what I understood):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df06e624709b6250"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "running_in_colab = 'google.colab' in str(get_ipython())\n",
    "if running_in_colab:\n",
    "    logger.info('You are running this on COLAB so installing the environment here')\n",
    "    os.chdir(\"/content\")    \n",
    "    !git clone https://github.com/petteriTeikari/minivess_mlops.git\n",
    "    !pip install poetry\n",
    "    os.chdir(\"/content/minivess_mlops\")\n",
    "    !poetry config virtualenvs.in-project true\n",
    "    !poetry install\n",
    "    !poetry shell\n",
    "else:\n",
    "    logger.info('Assuming that you are runnign this from IDE, '\n",
    "                'or some other environment where you have your Jupyter kernel created from Poetry files')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23525ddc876b758d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import helper subfunction(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aed4aabb6c2f770"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_dataloaders(experim_dataloaders: dict):\n",
    "    # Get the \"validation\" and \"train\" dataloaders from the dictionary\n",
    "    fold_name = 'fold0'\n",
    "    split_names = list(experim_dataloaders[fold_name].keys())\n",
    "    fold_key = experim_dataloaders.get(fold_name)\n",
    "    if fold_key is not None:\n",
    "        try:\n",
    "            train = experim_dataloaders[fold_name]['TRAIN']\n",
    "            val = experim_dataloaders[fold_name]['VAL']['MINIVESS']\n",
    "        except Exception as e:\n",
    "            raise IOError('Could not get the dataloaders from the dictionary, error = {}'.format(e))\n",
    "    else:\n",
    "        raise IOError('Fold name = \"{}\" not found in the dataloaders dictionary'.format(fold_name))\n",
    "    return train, val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T00:04:59.375331268Z",
     "start_time": "2023-10-25T00:04:59.351064267Z"
    }
   },
   "id": "3e05f12233738a40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Input arguments for the training (you can add all the input arguments supported by `run_training.py` here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "285ff9d623a96c9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_args = ['-c', 'tutorials/train_demo']\n",
    "\n",
    "# Fake these as coming from the command line to match the main code (run_training.py)\n",
    "sys.argv = ['notebook_run']  # Jupyter has all the extra crap, so replace that with this\n",
    "for sysargv in input_args:\n",
    "    sys.argv.append(sysargv)\n",
    "args = parse_args_to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-25T00:04:59.358108314Z"
    }
   },
   "id": "cfe20cf4816832a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the config with Hydra from the .yaml file(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f922a0c5e5c340"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config, exp_run = import_config(args=args, task_cfg_name=args['task_config_file'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c432cc673828082d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the dataloaders (now the data augmentations are here as well as data transformations)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40c67cdc100d7ebc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, _, experim_dataloaders, exp_run = (\n",
    "        define_experiment_data(config=config,\n",
    "                               exp_run=exp_run))\n",
    "\n",
    "# Get the \"validation\" and \"train\" dataloaders from the dictionary\n",
    "train, val = get_dataloaders(experim_dataloaders)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e231509f5afb185"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you are ready to train your new model that you just wanna quickly test without\n",
    "wanting to have a battle with the config .YAML files\n",
    "Add maybe some fastai demo with MLflow autologging:\n",
    "https://github.com/mlflow/mlflow/blob/master/examples/fastai/train.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "730a808f93390d1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate the dataloaders for demo\n",
    "no_of_epochs = 3\n",
    "logger.info('Training for {} epochs'.format(no_of_epochs))\n",
    "for epoch in range(no_of_epochs):\n",
    "    \n",
    "    logger.info('Epoch {}/{}'.format(epoch, no_of_epochs - 1))\n",
    "\n",
    "    # Train\n",
    "    logger.info('train with {} batches'.format(len(train))) \n",
    "    for i, batch in enumerate(train):\n",
    "        images, mask = batch['image'], batch['label']\n",
    "\n",
    "    # Validation\n",
    "    logger.info('validate with {} batches'.format(len(train))) \n",
    "    for j, batch in enumerate(val):\n",
    "        images, mask = batch['image'], batch['label']\n",
    "\n",
    "logger.info('Training done!')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ee4ad4c2e241e65b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "70cee075ca5bd2f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "poetry_kernel",
   "language": "python",
   "display_name": "poetry_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
