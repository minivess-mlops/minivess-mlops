{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use a custom model quickly\n",
    "\n",
    "Reuse the data(loader) from the \"ML pipe\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dba488f6c9898c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the libraries needed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e42e792c194f5e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:20:52.762001966Z",
     "start_time": "2023-10-25T01:20:52.759119044Z"
    }
   },
   "id": "c200b12aa14f2287"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you run this Notebook on Colab, you need to install the Virtual Environment with Poetry yourself (what I understood):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df06e624709b6250"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming that you are runnign this from IDE, or some other environment where you have your Jupyter kernel created from Poetry files\n"
     ]
    }
   ],
   "source": [
    "running_in_colab = 'google.colab' in str(get_ipython())\n",
    "if running_in_colab:\n",
    "    print('You are running this on COLAB so installing the environment here')\n",
    "    os.chdir(\"/content\")    \n",
    "    !git clone https://github.com/petteriTeikari/minivess_mlops.git\n",
    "    !pip install poetry\n",
    "    os.chdir(\"/content/minivess_mlops\")\n",
    "    !poetry config virtualenvs.in-project true\n",
    "    # Running \"!poetry install --no-ansi\" is needed or not?\n",
    "    !poetry install\n",
    "    !poetry shell\n",
    "    # https://stackoverflow.com/a/65440080/6412152\n",
    "    sys.path.insert(0,'/content/minivess_mlops')\n",
    "else:\n",
    "    print('Assuming that you are runnign this from IDE,\\n'\n",
    "          'or some other environment where you have your Jupyter kernel created from Poetry files')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:20:52.763416179Z",
     "start_time": "2023-10-25T01:20:52.760867095Z"
    }
   },
   "id": "23525ddc876b758d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the other modules now available from Poetry environment and from the Github repo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8986f81887cf72c4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petteri/.cache/pypoetry/virtualenvs/mlops-nuJNTY7i-py3.8/lib/python3.8/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/petteri/.cache/pypoetry/virtualenvs/mlops-nuJNTY7i-py3.8/lib/python3.8/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "Failed to load image Python extension: '/home/petteri/.cache/pypoetry/virtualenvs/mlops-nuJNTY7i-py3.8/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "PyTorch is available but CUDA is not. Defaulting to SciPy for SVD\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "from src.run_training import parse_args_to_dict\n",
    "from src.training.experiment import define_experiment_data\n",
    "from src.utils.config_utils import import_config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:20:55.397017427Z",
     "start_time": "2023-10-25T01:20:52.761204549Z"
    }
   },
   "id": "18c3a271cdfbd652"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import helper subfunction(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aed4aabb6c2f770"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_dataloaders(experim_dataloaders: dict):\n",
    "    # Get the \"validation\" and \"train\" dataloaders from the dictionary\n",
    "    fold_name = 'fold0'\n",
    "    split_names = list(experim_dataloaders[fold_name].keys())\n",
    "    fold_key = experim_dataloaders.get(fold_name)\n",
    "    if fold_key is not None:\n",
    "        try:\n",
    "            train = experim_dataloaders[fold_name]['TRAIN']\n",
    "            val = experim_dataloaders[fold_name]['VAL']['MINIVESS']\n",
    "        except Exception as e:\n",
    "            raise IOError('Could not get the dataloaders from the dictionary, error = {}'.format(e))\n",
    "    else:\n",
    "        raise IOError('Fold name = \"{}\" not found in the dataloaders dictionary'.format(fold_name))\n",
    "    return train, val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:20:55.443359544Z",
     "start_time": "2023-10-25T01:20:55.398820453Z"
    }
   },
   "id": "3e05f12233738a40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Input arguments for the training (you can add all the input arguments supported by `run_training.py` here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "285ff9d623a96c9f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 02:20:55.408 | INFO     | src.run_training:parse_args_to_dict:73 - Parsed input arguments:\n",
      "2023-10-25 02:20:55.409 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -   task_config_file: tutorials/train_demo\n",
      "2023-10-25 02:20:55.409 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -   run_mode: train\n",
      "2023-10-25 02:20:55.410 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -   data_dir: /mnt/minivess-dvc-cache\n",
      "2023-10-25 02:20:55.410 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -   output_dir: /mnt/minivess-artifacts\n",
      "2023-10-25 02:20:55.411 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -   s3_mount: False\n",
      "2023-10-25 02:20:55.411 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -   local_rank: 0\n",
      "2023-10-25 02:20:55.411 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -   project_name: MINIVESS_segmentation_TEST\n"
     ]
    }
   ],
   "source": [
    "input_args = ['-c', 'tutorials/train_demo']\n",
    "\n",
    "# Fake these as coming from the command line to match the main code (run_training.py)\n",
    "sys.argv = ['notebook_run']  # Jupyter has all the extra crap, so replace that with this\n",
    "for sysargv in input_args:\n",
    "    sys.argv.append(sysargv)\n",
    "args = parse_args_to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:20:55.444487026Z",
     "start_time": "2023-10-25T01:20:55.443204408Z"
    }
   },
   "id": "cfe20cf4816832a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the config with Hydra from the .yaml file(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f922a0c5e5c340"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 02:20:55.710 | INFO     | src.utils.config_utils:hydra_import_config:89 - Initializing Hydra with config_path = \"/home/petteri/PycharmProjects/minivess_mlops/notebooks/../configs\", job_name = \"MINIVESS_segmentation_TEST\", version_base = \"1.2\"\n",
      "2023-10-25 02:20:55.711 | INFO     | src.utils.config_utils:hydra_import_config:91 - Hydra overrides list = ['+tutorials=train_demo']\n",
      "2023-10-25 02:20:55.711 | WARNING  | src.utils.config_utils:set_up_environment:283 - No Nvidia CUDA GPU found, training on CPU instead!\n",
      "2023-10-25 02:20:55.712 | WARNING  | src.utils.config_utils:set_up_experiment_run:138 - Skipping realtime AWS S3 write, and writing run artifacts to a local non-mounted dir\n",
      "2023-10-25 02:20:55.712 | DEBUG    | src.utils.config_utils:get_mounts_from_args:409 - Getting mount names from the args\n",
      "2023-10-25 02:20:55.713 | INFO     | ml_tests.mount_tests:debug_mounts:9 - Username = petteri, UID = 1000, GID = 1000\n",
      "2023-10-25 02:20:55.713 | DEBUG    | ml_tests.mount_tests:debug_mounts:12 - MOUNT: /mnt/minivess-dvc-cache\n",
      "2023-10-25 02:20:55.714 | DEBUG    | ml_tests.mount_tests:debug_mounts:19 -  owned by petteri:petteri (owner:group)\n",
      "2023-10-25 02:20:55.715 | DEBUG    | ml_tests.mount_tests:debug_mounts:22 -  owned by 1000:1000 (owner:group)\n",
      "2023-10-25 02:20:55.716 | DEBUG    | ml_tests.mount_tests:debug_mounts:23 -  mount permissions: 0755\n",
      "2023-10-25 02:20:55.716 | DEBUG    | ml_tests.mount_tests:debug_mounts:24 -  read access = True\n",
      "2023-10-25 02:20:55.717 | DEBUG    | ml_tests.mount_tests:debug_mounts:25 -  write access = True\n",
      "2023-10-25 02:20:55.718 | DEBUG    | ml_tests.mount_tests:debug_mounts:26 -  execution access = True\n",
      "2023-10-25 02:20:55.718 | DEBUG    | ml_tests.mount_tests:debug_mounts:27 -  existence of dir = True\n",
      "2023-10-25 02:20:55.719 | DEBUG    | ml_tests.mount_tests:debug_mounts:30 - Trying to write to the mount (write access was OK)\n",
      "2023-10-25 02:20:55.719 | DEBUG    | ml_tests.mount_tests:debug_mounts:47 - File write succesful!\n",
      "2023-10-25 02:20:55.720 | DEBUG    | ml_tests.mount_tests:debug_mounts:49 -  file_permission = 0664, 1000:1000\n",
      "2023-10-25 02:20:55.721 | DEBUG    | ml_tests.mount_tests:debug_mounts:59 - File delete succesful!\n",
      "2023-10-25 02:20:55.722 | DEBUG    | ml_tests.mount_tests:debug_mounts:12 - MOUNT: /mnt/minivess-artifacts_local\n",
      "2023-10-25 02:20:55.722 | DEBUG    | ml_tests.mount_tests:debug_mounts:19 -  owned by petteri:petteri (owner:group)\n",
      "2023-10-25 02:20:55.723 | DEBUG    | ml_tests.mount_tests:debug_mounts:22 -  owned by 1000:1000 (owner:group)\n",
      "2023-10-25 02:20:55.724 | DEBUG    | ml_tests.mount_tests:debug_mounts:23 -  mount permissions: 0775\n",
      "2023-10-25 02:20:55.724 | DEBUG    | ml_tests.mount_tests:debug_mounts:24 -  read access = True\n",
      "2023-10-25 02:20:55.725 | DEBUG    | ml_tests.mount_tests:debug_mounts:25 -  write access = True\n",
      "2023-10-25 02:20:55.725 | DEBUG    | ml_tests.mount_tests:debug_mounts:26 -  execution access = True\n",
      "2023-10-25 02:20:55.726 | DEBUG    | ml_tests.mount_tests:debug_mounts:27 -  existence of dir = True\n",
      "2023-10-25 02:20:55.726 | DEBUG    | ml_tests.mount_tests:debug_mounts:30 - Trying to write to the mount (write access was OK)\n",
      "2023-10-25 02:20:55.727 | DEBUG    | ml_tests.mount_tests:debug_mounts:47 - File write succesful!\n",
      "2023-10-25 02:20:55.727 | DEBUG    | ml_tests.mount_tests:debug_mounts:49 -  file_permission = 0664, 1000:1000\n",
      "2023-10-25 02:20:55.727 | DEBUG    | ml_tests.mount_tests:debug_mounts:59 - File delete succesful!\n",
      "2023-10-25 02:20:55.728 | INFO     | src.utils.config_utils:set_up_run_params:184 - Save the run-specific parameters to exp_run[\"run\"]\n",
      "2023-10-25 02:20:55.729 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    hyperparam_name: train_demo\n",
      "2023-10-25 02:20:55.730 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    hyperparam_base_name: train_demo\n",
      "2023-10-25 02:20:55.730 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    output_base_dir: /mnt/minivess-artifacts_local\n",
      "2023-10-25 02:20:55.731 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    output_experiments_base_dir: /mnt/minivess-artifacts_local/experiments\n",
      "2023-10-25 02:20:55.731 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    output_experiment_dir: /mnt/minivess-artifacts_local/experiments/train_demo\n",
      "2023-10-25 02:20:55.732 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    output_wandb_dir: /mnt/minivess-artifacts_local/WANDB\n",
      "2023-10-25 02:20:55.732 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    output_mlflow_dir: /mnt/minivess-artifacts_local/MLflow\n",
      "2023-10-25 02:20:55.733 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    config_hash: 7ea1d3f41089ca8a2e2679a7d184dea3\n",
      "2023-10-25 02:20:55.733 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    start_time: 20231025-0120GMT\n",
      "2023-10-25 02:20:55.734 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    src_dir: /home/petteri/PycharmProjects/minivess_mlops/notebooks\n",
      "2023-10-25 02:20:55.735 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    repo_dir: /home/petteri/PycharmProjects/minivess_mlops/notebooks/..\n",
      "2023-10-25 02:20:55.735 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    repeat_artifacts: {}\n",
      "2023-10-25 02:20:55.736 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    ensemble_artifacts: {}\n",
      "2023-10-25 02:20:55.736 | INFO     | src.utils.general_utils:print_dict_to_logger:40 -    fold_dir: {}\n",
      "2023-10-25 02:20:55.737 | INFO     | src.utils.config_utils:define_hyperparam_run_params:330 - Hand-picking the keys/subdicts from \"config\" that are logged as hyperparameters for MLflow/WANDB\n",
      "2023-10-25 02:20:55.739 | WARNING  | src.utils.config_utils:parse_training_params:352 - Skipping the training, not parsing training hyperparameters\n",
      "2023-10-25 02:20:55.740 | INFO     | src.utils.config_utils:define_hyperparams_from_config:228 - Save the derived hyperparameters to config[\"hyperparameters\"]\n",
      "2023-10-25 02:20:55.741 | INFO     | src.utils.config_utils:define_hyperparams_from_config:229 - {}\n",
      "2023-10-25 02:20:55.742 | INFO     | src.utils.config_utils:use_dict_hash_in_names:213 - Unique hyperparam name with hash\n",
      "2023-10-25 02:20:55.742 | INFO     | src.utils.config_utils:use_dict_hash_in_names:214 -   hyperparam_name = \"train_demo_7ea1d3f41089ca8a2e2679a7d184dea3\"\n",
      "2023-10-25 02:20:55.743 | INFO     | src.utils.config_utils:use_dict_hash_in_names:215 -   output_experiment_dir = \"/mnt/minivess-artifacts_local/experiments/train_demo_7ea1d3f41089ca8a2e2679a7d184dea3\"\n",
      "2023-10-25 02:20:55.745 | INFO     | src.utils.config_utils:set_up_log_files:251 - Log (loguru) will be saved to disk to \"/mnt/minivess-artifacts_local/experiments/train_demo_7ea1d3f41089ca8a2e2679a7d184dea3/log_train_demo.txt\"\n",
      "2023-10-25 02:20:55.747 | INFO     | src.utils.config_utils:set_up_log_files:255 - Stdout will be saved to disk to \"/mnt/minivess-artifacts_local/experiments/train_demo_7ea1d3f41089ca8a2e2679a7d184dea3/stdout_train_demo.txt\"\n",
      "2023-10-25 02:20:55.771 | INFO     | src.utils.metadata_utils:get_monai_config:85 - MONAI | LIBRARY VERSIONS:\n",
      "2023-10-25 02:20:55.772 | INFO     | src.utils.metadata_utils:get_monai_config:87 -   MONAI: 1.2.0\n",
      "2023-10-25 02:20:55.773 | INFO     | src.utils.metadata_utils:get_monai_config:87 -   Numpy: 1.24.4\n",
      "2023-10-25 02:20:55.774 | INFO     | src.utils.metadata_utils:get_monai_config:87 -   Pytorch: 2.0.0+cu117\n",
      "2023-10-25 02:20:55.774 | INFO     | src.utils.metadata_utils:get_monai_config:89 - MONAI | OPTIONAL LIBRARY VERSIONS:\n",
      "2023-10-25 02:20:55.775 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   Pytorch Ignite: 0.4.12\n",
      "2023-10-25 02:20:55.776 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   ITK: 5.3.0\n",
      "2023-10-25 02:20:55.776 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   Nibabel: 5.1.0\n",
      "2023-10-25 02:20:55.777 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   scikit-image: 0.21.0\n",
      "2023-10-25 02:20:55.777 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   Pillow: 10.0.1\n",
      "2023-10-25 02:20:55.778 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   Tensorboard: 2.14.0\n",
      "2023-10-25 02:20:55.778 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   gdown: 4.7.1\n",
      "2023-10-25 02:20:55.779 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   TorchVision: 0.16.0+cu121\n",
      "2023-10-25 02:20:55.779 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   tqdm: 4.66.1\n",
      "2023-10-25 02:20:55.780 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   lmdb: 1.4.1\n",
      "2023-10-25 02:20:55.780 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   psutil: 5.9.5\n",
      "2023-10-25 02:20:55.780 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   pandas: 2.0.3\n",
      "2023-10-25 02:20:55.781 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   einops: 0.6.1\n",
      "2023-10-25 02:20:55.781 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   transformers: 4.34.0\n",
      "2023-10-25 02:20:55.781 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   mlflow: 2.7.1\n",
      "2023-10-25 02:20:55.782 | INFO     | src.utils.metadata_utils:get_monai_config:91 -   pynrrd: 1.0.0\n",
      "2023-10-25 02:20:55.782 | INFO     | src.utils.metadata_utils:get_monai_config:93 - MONAI | SYSTEM:\n",
      "2023-10-25 02:20:55.783 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   System: Linux\n",
      "2023-10-25 02:20:55.783 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Linux version: Ubuntu 22.04.3 LTS\n",
      "2023-10-25 02:20:55.783 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Platform: Linux-6.2.0-34-generic-x86_64-with-glibc2.35\n",
      "2023-10-25 02:20:55.784 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Processor: x86_64\n",
      "2023-10-25 02:20:55.785 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Machine: x86_64\n",
      "2023-10-25 02:20:55.785 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Python version: 3.8.18\n",
      "2023-10-25 02:20:55.786 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Process name: python\n",
      "2023-10-25 02:20:55.786 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Command: ['/home/petteri/.cache/pypoetry/virtualenvs/mlops-nuJNTY7i-py3.8/bin/python', '-m', 'ipykernel_launcher', '-f', '/home/petteri/.local/share/jupyter/runtime/kernel-d626e691-2f7e-470a-81e7-ca1ceecaa3df.json']\n",
      "2023-10-25 02:20:55.786 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Open files: [popenfile(path='/home/petteri/.ipython/profile_default/history.sqlite', fd=46, position=0, mode='r+', flags=688130), popenfile(path='/home/petteri/.ipython/profile_default/history.sqlite', fd=47, position=0, mode='r+', flags=688130), popenfile(path='/home/petteri/minivess-artifacts_local/experiments/train_demo_7ea1d3f41089ca8a2e2679a7d184dea3/log_train_demo.txt', fd=55, position=141470, mode='a', flags=558081), popenfile(path='/home/petteri/minivess-artifacts_local/experiments/train_demo_7ea1d3f41089ca8a2e2679a7d184dea3/stdout_train_demo.txt', fd=58, position=0, mode='w', flags=557057)]\n",
      "2023-10-25 02:20:55.787 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Num physical CPUs: 12\n",
      "2023-10-25 02:20:55.787 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Num logical CPUs: 16\n",
      "2023-10-25 02:20:55.788 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Num usable CPUs: 16\n",
      "2023-10-25 02:20:55.788 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   CPU usage (%): [26.8, 7.7, 47.6, 7.7, 25.5, 6.8, 45.3, 6.5, 13.0, 13.6, 10.2, 9.0, 8.4, 8.6, 9.3, 9.3]\n",
      "2023-10-25 02:20:55.788 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   CPU freq. (MHz): 2297\n",
      "2023-10-25 02:20:55.789 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Load avg. in last 1, 5, 15 mins (%): [10.3, 8.3, 7.1]\n",
      "2023-10-25 02:20:55.789 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Disk usage (%): 38.1\n",
      "2023-10-25 02:20:55.790 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Avg. sensor temp. (Celsius): UNKNOWN for given OS\n",
      "2023-10-25 02:20:55.791 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Total physical memory (GB): 31.0\n",
      "2023-10-25 02:20:55.792 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Available memory (GB): 14.8\n",
      "2023-10-25 02:20:55.792 | INFO     | src.utils.metadata_utils:get_monai_config:95 -   Used memory (GB): 12.5\n",
      "2023-10-25 02:20:55.793 | INFO     | src.utils.metadata_utils:get_monai_config:97 - MONAI | GPU:\n",
      "2023-10-25 02:20:55.794 | INFO     | src.utils.metadata_utils:get_monai_config:99 -   Num GPUs: 0\n",
      "2023-10-25 02:20:55.795 | INFO     | src.utils.metadata_utils:get_monai_config:99 -   Has CUDA: False\n",
      "2023-10-25 02:20:55.795 | INFO     | src.utils.metadata_utils:get_monai_config:99 -   cuDNN enabled: True\n",
      "2023-10-25 02:20:55.796 | INFO     | src.utils.metadata_utils:get_monai_config:99 -   cuDNN version: 8500\n",
      "2023-10-25 02:20:55.796 | WARNING  | src.utils.metadata_utils:clean_monai_dict_for_omegaconf:118 - MONAI metadata key = \"Command\" not cleaned to OmegaConf as its type was too \"exotic\", type = <class 'list'> (you see these on log though)\n",
      "2023-10-25 02:20:55.797 | WARNING  | src.utils.metadata_utils:clean_monai_dict_for_omegaconf:118 - MONAI metadata key = \"Open files\" not cleaned to OmegaConf as its type was too \"exotic\", type = <class 'list'> (you see these on log though)\n",
      "2023-10-25 02:20:55.797 | WARNING  | src.utils.metadata_utils:clean_monai_dict_for_omegaconf:118 - MONAI metadata key = \"CPU usage (%)\" not cleaned to OmegaConf as its type was too \"exotic\", type = <class 'list'> (you see these on log though)\n",
      "2023-10-25 02:20:55.798 | WARNING  | src.utils.metadata_utils:clean_monai_dict_for_omegaconf:118 - MONAI metadata key = \"Load avg. in last 1, 5, 15 mins (%)\" not cleaned to OmegaConf as its type was too \"exotic\", type = <class 'list'> (you see these on log though)\n",
      "2023-10-25 02:20:55.823 | INFO     | src.log_ML.mlflow_log:init_mlflow_logging:114 - Skipping MLflow Experiment tracking\n"
     ]
    }
   ],
   "source": [
    "config, exp_run = import_config(args=args, task_cfg_name=args['task_config_file'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:20:55.828772261Z",
     "start_time": "2023-10-25T01:20:55.443641502Z"
    }
   },
   "id": "c432cc673828082d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the dataloaders (now the data augmentations are here as well as data transformations)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40c67cdc100d7ebc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, _, experim_dataloaders, exp_run = (\n",
    "        define_experiment_data(config=config,\n",
    "                               exp_run=exp_run))\n",
    "\n",
    "# Get the \"validation\" and \"train\" dataloaders from the dictionary\n",
    "train, val = get_dataloaders(experim_dataloaders)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-25T01:20:55.829768832Z"
    }
   },
   "id": "e231509f5afb185"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you are ready to train your new model that you just wanna quickly test without\n",
    "wanting to have a battle with the config .YAML files\n",
    "\n",
    "Add maybe some fastai demo with MLflow autologging:\n",
    "[https://github.com/mlflow/mlflow/blob/master/examples/fastai/train.py](https://github.com/mlflow/mlflow/blob/master/examples/fastai/train.py)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "730a808f93390d1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate the dataloaders for demo\n",
    "no_of_epochs = 3\n",
    "logger.info('Training for {} epochs'.format(no_of_epochs))\n",
    "for epoch in range(no_of_epochs):\n",
    "    \n",
    "    logger.info('Epoch {}/{}'.format(epoch, no_of_epochs - 1))\n",
    "\n",
    "    # Train\n",
    "    logger.info('train with {} batches'.format(len(train))) \n",
    "    for i, batch in enumerate(train):\n",
    "        images, mask = batch['image'], batch['label']\n",
    "\n",
    "    # Validation\n",
    "    logger.info('validate with {} batches'.format(len(train))) \n",
    "    for j, batch in enumerate(val):\n",
    "        images, mask = batch['image'], batch['label']\n",
    "\n",
    "logger.info('Training done!')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ee4ad4c2e241e65b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
