decision_id: experiment_tracking
title: "Experiment Tracking"
description: >
  Which experiment tracking platform to use for logging metrics, parameters,
  artifacts, and model versions. The choice affects reproducibility depth,
  team collaboration patterns, and integration with the broader MLOps stack.
  Must support 3D medical imaging artifacts (NIfTI volumes, surface meshes,
  calibration plots).

decision_level: L3_technology
status: active
last_updated: 2026-02-23

options:
  - option_id: mlflow
    title: "MLflow"
    description: >
      Open-source experiment tracking with model registry. Self-hosted,
      no vendor lock-in. Supports custom artifacts, auto-logging, and
      DuckDB analytics overlay. Already the primary tracking platform.
    prior_probability: 0.45
    status: resolved
    implementation_status: implemented
    complements:
      - "reproducibility_standard.dvc_versioned"
      - "ensemble_methods.greedy_soup"
      - "llm_observability.langfuse"

  - option_id: wandb
    title: "Weights & Biases"
    description: >
      Cloud-native experiment tracking with rich visualization. Superior
      UI for comparing runs and viewing 3D volumes. Free tier for
      academics but vendor lock-in risk.
    prior_probability: 0.25
    status: viable
    implementation_status: not_started
    constraints:
      - "Cloud dependency (self-hosted option exists but complex)"
      - "Vendor lock-in for artifacts"
      - "Free tier limitations"

  - option_id: neptune
    title: "Neptune.ai"
    description: >
      Experiment tracking focused on metadata management. Good for
      large-scale experiment comparison. Less community adoption than
      MLflow/W&B.
    prior_probability: 0.15
    status: viable
    implementation_status: not_started
    constraints:
      - "Smaller community than MLflow/W&B"
      - "Cloud-first architecture"

  - option_id: clearml
    title: "ClearML"
    description: >
      Open-source MLOps platform with experiment tracking, orchestration,
      and data management. Self-hosted option. Less medical imaging
      community adoption.
    prior_probability: 0.15
    status: viable
    implementation_status: not_started
    constraints:
      - "Overlaps with existing orchestration tools"
      - "Smaller ecosystem of integrations"

conditional_on:
  - parent_decision_id: reproducibility_standard
    influence_strength: moderate
    conditional_table:
      - given_parent_option: full_deterministic
        then_probabilities:
          mlflow: 0.40
          wandb: 0.25
          neptune: 0.20
          clearml: 0.15
      - given_parent_option: dvc_versioned
        then_probabilities:
          mlflow: 0.50
          wandb: 0.25
          neptune: 0.10
          clearml: 0.15
      - given_parent_option: git_only
        then_probabilities:
          mlflow: 0.35
          wandb: 0.30
          neptune: 0.20
          clearml: 0.15

  - parent_decision_id: config_management
    influence_strength: weak
    conditional_table:
      - given_parent_option: hydra_zen
        then_probabilities:
          mlflow: 0.50
          wandb: 0.25
          neptune: 0.10
          clearml: 0.15
      - given_parent_option: dynaconf
        then_probabilities:
          mlflow: 0.45
          wandb: 0.25
          neptune: 0.15
          clearml: 0.15
      - given_parent_option: pydantic_settings
        then_probabilities:
          mlflow: 0.40
          wandb: 0.25
          neptune: 0.15
          clearml: 0.20
      - given_parent_option: dual_config
        then_probabilities:
          mlflow: 0.50
          wandb: 0.20
          neptune: 0.15
          clearml: 0.15

archetype_weights:
  solo_researcher:
    probability_overrides:
      mlflow: 0.45
      wandb: 0.30
      neptune: 0.15
      clearml: 0.10
    rationale: "Solo researchers value free self-hosted (MLflow) or polished UI (W&B)"
  lab_group:
    probability_overrides:
      mlflow: 0.40
      wandb: 0.30
      neptune: 0.15
      clearml: 0.15
    rationale: "Lab groups need collaboration features; W&B UI is strong for team use"
  clinical_deployment:
    probability_overrides:
      mlflow: 0.50
      wandb: 0.15
      neptune: 0.15
      clearml: 0.20
    rationale: "Clinical prefers self-hosted MLflow for data sovereignty and audit trails"

volatility:
  classification: stable
  last_assessed: 2026-02-23
  next_review: 2026-08-23
  change_drivers:
    - "MLflow 3.0 release"
    - "W&B self-hosted pricing changes"
    - "DuckDB-MLflow analytics maturity"
    - "New tracking platforms (Comet ML, etc.)"

domain_applicability:
  vascular_segmentation: 1.0
  cardiac_imaging: 1.0
  neuroimaging: 1.0
  general_medical: 1.0

rationale: >
  MLflow (0.45) is resolved as the primary platform (Zaharia et al., 2018). It is
  self-hosted, open-source, and already integrated with DVC, Hydra-zen configs,
  and DuckDB analytics. MLOps surveys (Kreuzberger et al., 2023; Ruf et al., 2021)
  confirm MLflow's position as the leading open-source experiment tracker. W&B (0.25)
  is the strongest alternative with superior visualization but introduces cloud
  dependency. Neptune (0.15) and ClearML (0.15) are viable alternatives with smaller
  communities in medical imaging.

references:
  - citation_key: zaharia2018mlflow
    relevance: "Foundational MLflow paper â€” the implemented experiment tracking platform"
    supports_options:
      - mlflow
  - citation_key: kreuzberger2023mlops
    relevance: "MLOps survey positioning experiment tracking as a core component"
    supports_options:
      - mlflow
      - wandb
      - neptune
      - clearml
  - citation_key: ruf2021demystifying
    relevance: "Benchmarks 26 open-source MLOps tools including experiment trackers"
    supports_options:
      - mlflow
      - wandb

tags:
  - experiment-tracking
  - mlops
  - mlflow
  - reproducibility
  - resolved
