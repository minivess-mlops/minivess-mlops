name: Test EE (Data)

on:
  # At the moment this is part of the "CI suite", so you first build the image for training (build_train_image.yml),
  # and you also want to test whether the data gets loaded again, and the training mechanics work
  # i.e. this test does not need to be triggered by Push
  # https://www.r-bloggers.com/2020/07/running-github-actions-sequentially/
  repository_dispatch:
    types: [ trigger-test-dataload ]

jobs:
  test_dataload:
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v2 # checkout the repository content
        with:
          ref: ${{ github.event.client_payload.sha }}
      - name: dockerhub login
        env:
          DOCKERHUB_USER: ${{secrets.DOCKERHUB_USERNAME}}
          DOCKERHUB_PASSWORD: ${{secrets.DOCKERHUB_PASSWORD}}
        run:
          docker login -u $DOCKERHUB_USER -p $DOCKERHUB_PASSWORD
      - name: pull Docker image
        run: docker pull petteriteikari/minivess-mlops-train:latest
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{secrets.AWS_ACCESS_KEY_ID}}
          aws-secret-access-key: ${{secrets.AWS_SECRET_ACCESS_KEY}}
          aws-region: eu-north-1
      - name: Create AWS credentials on-the-fly
        run: |
          mkdir -p ~/.aws
          echo "[default]" > ~/.aws/credentials
          echo "aws_access_key_id = ${{secrets.AWS_ACCESS_KEY_ID}}" >> ~/.aws/credentials
          echo "aws_secret_access_key = ${{secrets.AWS_SECRET_ACCESS_KEY}}" >> ~/.aws/credentials
      - name: Check diskspace before DVC pull
        run: sudo df -h
      - name: Install DVC
        uses: iterative/setup-dvc@v1
      - name: Create directory for DVC cache
        run: mkdir -p minivess-dvc-cache
      - name: Pull data from DVC
        #dvc remote modify remote_storage access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        #dvc remote modify remote_storage secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |          
          dvc config cache.dir minivess-dvc-cache
          dvc pull
      - name: Check diskspace after DVC pull
        run: sudo df -h
      - name: Create directory for artifacts
        run: mkdir -p minivess-artifacts
      - name: Print Docker version
        run: docker version
      - name: Testing data loading (training_run)
        env:
          MLFLOW_USER: ${{secrets.MLFLOW_USERNAME}}
          MLFLOW_PASSWORD: ${{secrets.MLFLOW_PASSWORD}}
        # With the mount, when the write permissions work
        # docker run -v ${HOME}/.aws:/home/minivessuser/.aws:ro -e S3_ARTIFACTS=minivess-artifacts -e DOCKER_ARTIFACTS=/mnt/minivess-artifacts -e S3_CACHE=minivess-dvc-cache -e DOCKER_CACHE=/mnt/minivess-dvc-cache --privileged --cap-add SYS_ADMIN --device /dev/fuse petteriteikari/minivess-mlops-train -c train_task_test.yaml -run test_dataload
        run: >
          docker run -v ${HOME}/.aws:/home/minivessuser/.aws:ro petteriteikari/minivess-mlops-train -c task_config.yaml -run test_dataload -no-s3
      # TODO! Could refactor this without this chaining
      - name: Trigger next workflow (test train)
        if: success()
        uses: peter-evans/repository-dispatch@v1
        with:
          token: ${{ secrets.REPO_GHA_PAT }}
          repository: ${{ github.repository }}
          event-type: trigger-test-train
          client-payload: '{"ref": "${{ github.ref }}", "sha": "${{ github.sha }}"}'

