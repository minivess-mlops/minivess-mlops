# Graph-Topology Debug (Short Validation) Config
# ---------------------------------------------------------------------------
# "Debug-long-and-small" mode: validates loss convergence with minimal data.
# Unlike the 1-epoch debug mode, this trains enough epochs to detect issues.
#
# Purpose:
#   - Verify all 5 graph-topology losses produce finite, decreasing loss
#   - Detect NaN/Inf during training before committing to full 100-epoch sweep
#   - Validate fold-robustness with 3-fold CV
#
# Parameters:
#   - 6 total volumes (indices 0-5), 3-fold CV → 4 train + 2 val per fold
#   - 6 epochs per fold (enough to see convergence trend)
#   - batch_size 1 (minimum memory)
#
# Estimated runtime: 5 losses × 3 folds × 6 epochs × ~2 min/epoch ≈ 3 hours
#
# See docs/planning/novel-loss-debugging-plan.xml for full validation plan.
# ---------------------------------------------------------------------------

experiment_name: dynunet_graph_topology_debug
model: dynunet
losses:
  - dice_ce
  - cbdice_cldice
  - graph_topology
  - skeleton_recall
  - betti_matching
compute: gpu_low
data_dir: data/raw/minivess
num_folds: 3
max_epochs: 6
seed: 42
debug: false  # NOT the existing 1-epoch debug; this is a proper short run
memory_limit_gb: 24
monitor_interval: 5

# Subset volumes for speed
volume_indices: [0, 1, 2, 3, 4, 5]

# ---------------------------------------------------------------------------
# Checkpoint (relaxed for debug)
# ---------------------------------------------------------------------------
checkpoint:
  tracked_metrics:
    - {name: val_loss, direction: minimize, patience: 30}
    - {name: val_dice, direction: maximize, patience: 30}
    - {name: val_cldice, direction: maximize, patience: 30}
    - {name: val_compound_nsd_cldice, direction: maximize, patience: 30}
  primary_metric: val_compound_nsd_cldice
  min_delta: 0.0001
  min_epochs: 1
  save_last: true
  save_history: false

# ---------------------------------------------------------------------------
# Validation criteria (checked after training)
# ---------------------------------------------------------------------------
# After 6 epochs, verify:
#   1. Loss at epoch 6 < loss at epoch 1
#   2. No NaN/Inf in any logged metric
#   3. val_dice > 0 (model learned something)
#   4. Gradients are non-zero
